{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0acfa41c-166a-47a3-b9b7-63f69bfbb21e",
   "metadata": {},
   "source": [
    "<font size=7>  $\\textrm{Tutorial} \\ 2$  </font>\n",
    "\n",
    "<font size=5>  $\\textrm{Supervised learning phase separation}$   </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0d90c5-ebb0-40a5-96d6-92c3aa256b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67f38e4f-a319-4563-a27d-ddf2a2e6212a",
   "metadata": {},
   "source": [
    "<font size=4>  $\\textrm{We will try to learn the classification of phases into ferromagnetic/paramagnetic based on spin snapshots.}$   </font>\n",
    "\n",
    "<font size=4>  $\\textrm{Our goal: Train a machine learning model that will take in a spin configuration and tell us which phase it lives in for the Ising Hamiltonian.}$   </font>\n",
    "\n",
    "\n",
    "<font size=5> $H = -J \\sum_{\\langle i, j \\rangle}^{}  \\sigma_i^z \\sigma_{j}^z $</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fdd173-2a15-4a68-bf55-b1c24f0911f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37becf48-56ee-4901-9de8-ee8bee62c868",
   "metadata": {},
   "source": [
    "<font size=5>  $\\textrm{a) Preparing the data}$   </font>\n",
    "\n",
    "<font size=4>  $\\textrm{For this we will use the following function, that uses the Metropolis Monte Carlo algorithm to generate the samples at a fixed temperature.}$   </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0233c150-75d1-4ef4-b8fa-b6559eac5c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11d3b8c9-b378-42bd-8907-31132e52df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 10 # number of lattice sites L x L\n",
    "N_spins = L**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "27770947-96cc-4daf-b86d-0b7520b67396",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Store each spin's four nearest neighbours in a neighbours array (using periodic boundary conditions):\n",
    "neighbours = np.zeros((N_spins,4), dtype=np.int64)\n",
    "for i in range(N_spins):\n",
    "    #neighbour to the right:\n",
    "    neighbours[i,0]=i+1\n",
    "    if i%L==(L-1):\n",
    "        neighbours[i,0]=i+1-L\n",
    "  \n",
    "    #upwards neighbour:\n",
    "    neighbours[i,1]=i+L\n",
    "    if i >= (N_spins-L):\n",
    "        neighbours[i,1]=i+L-N_spins\n",
    "\n",
    "    #left neighbour:\n",
    "    neighbours[i,2] = i-1\n",
    "    if i%L==0:\n",
    "        neighbours[i,2]=i-1+L\n",
    "\n",
    "    #downwards neighbour:\n",
    "    neighbours[i,3] = i-L\n",
    "    if i < L:\n",
    "        neighbours[i,3]= N_spins-L+i\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7375d72e-1512-4785-9d2a-73d4895c608f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "856328f7-a6f9-44e5-9b1b-9288fc2df963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEnergy(config):\n",
    "    '''Energy of a given configuration'''\n",
    "    energy = 0\n",
    "    for i in range(len(config)):\n",
    "        for j in range(len(config)):\n",
    "            S = config[i,j]\n",
    "            nb = config[(i+1)%N, j] + config[i,(j+1)%N] + config[(i-1)%N, j] + config[i,(j-1)%N]\n",
    "            energy += -nb*S\n",
    "    return energy/4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0856c92c-6cec-484a-84a6-fdbd3c1bf145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_step(spins, beta, J=1):\n",
    "    \"\"\"\n",
    "    Perform one step of the Metropolis algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "        spins (np.array): Current configuration of spins.\n",
    "        T (float): Temperature of the system.\n",
    "        J (float): Interaction energy coefficient.\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Updated configuration of spins.\n",
    "    \"\"\"\n",
    "    N = len(spins)\n",
    "    i = np.random.randint(N)  # Randomly pick a spin to flip\n",
    "    spins[i] *= -1            # Flip the spin\n",
    "    \n",
    "\n",
    "    delta_E = -2 * J * spins[i] * (spins[neighbours[i,0]] + spins[neighbours[i,1]] + spins[neighbours[i,2]] + spins[neighbours[i,3]])\n",
    "\n",
    "\n",
    "    # Metropolis criterion\n",
    "    if delta_E < 0 or np.random.rand() < np.exp(-1*delta_E * beta):\n",
    "        # Accept the flip\n",
    "        return spins\n",
    "    else:\n",
    "        # Revert the flip (reject)\n",
    "        spins[i] *= -1\n",
    "        return spins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "361ebbf1-5180-4e40-b502-55a02e50d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_metropolis(N, beta,numSamples,J=1, sample_interval=10):\n",
    "    \"\"\"\n",
    "    Run the Metropolis Monte Carlo algorithm to sample spin configurations after allowing the system to equilibrate,\n",
    "    and with a specified interval between samples to reduce autocorrelation.\n",
    "    \n",
    "    Parameters:\n",
    "        N (int): Lattice size\n",
    "        T (float): Temperature.\n",
    "        J (float): Interaction energy coefficient.\n",
    "        steps (int): Total number of Metropolis steps to perform.\n",
    "        equilibration_steps (int): Number of steps to discard at the start to allow the system to equilibrate.\n",
    "        sample_interval (int): Interval of steps between collecting samples to reduce autocorrelation.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of sampled spin configurations.\n",
    "    \"\"\"\n",
    "    \n",
    "    equilibration_steps=20*N**2\n",
    "    steps=equilibration_steps + sample_interval*numSamples\n",
    "    \n",
    "    spins = np.random.choice([-1, 1], size=N**2)  # Initial random spins\n",
    "    samples = []\n",
    "    \n",
    "    for step in range(steps):\n",
    "        spins = metropolis_step(spins, beta, J)  \n",
    "        \n",
    "        # Only start collecting samples after the equilibration period\n",
    "        if step >= equilibration_steps and (step - equilibration_steps) % sample_interval == 0:\n",
    "            samples.append(spins.copy())  # Collect samples at specified intervals\n",
    "\n",
    "        if step%200 == 0:\n",
    "            spins *= -1 #Global spin flip to avoid studying just 1 basin\n",
    "    \n",
    "    return np.array(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b06b496b-fb30-4b76-bc2d-96689ad845af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the ferromagnetic phase data\n",
    "beta = 1/(1.5) # Inverse Temperature\n",
    "number_samples = 5000\n",
    "samples_ferro = run_metropolis(L, beta,number_samples,sample_interval=10*N_spins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbae03ff-64e9-406e-8019-3b3405da2ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ferro = np.zeros(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f96409d7-bdd2-4d3c-b90c-5467cd68f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the paramagnetic phase data\n",
    "beta = 1/(5) # Inverse Temperature\n",
    "number_samples = 5000\n",
    "samples_para = run_metropolis(L, beta,number_samples,sample_interval=10*N_spins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0947cbc9-6e1e-459f-abeb-a0910fd969be",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_para = np.ones(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3f1ea4-58d9-4a61-86d9-2798d9866e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8c7d8d-6356-45dc-ab7a-fc290398a2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e904d968-6e29-4df8-bbea-72d18da52103",
   "metadata": {},
   "source": [
    "<font size=4>  $\\textrm{We will also go ahead and generate two smaller sets of 2500 each as a test data set. These won't be used for training but rather to validate if our model is learning correctly.}$   </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e5267e1-a424-4e32-b3a5-ae552ef11350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the ferromagnetic phase data\n",
    "beta = 1/(1.5) # Inverse Temperature\n",
    "number_samples = 2500\n",
    "samples_ferro_test = run_metropolis(L, beta,number_samples,sample_interval=10*N_spins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75a1d0af-2707-4caa-b34f-25e05e32e854",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ferro_test = np.zeros(2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0860f8f-a106-4fc1-b2b2-ec3c0fe5f9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54b7d94a-744e-45dd-adff-dc30031cbeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the paramagnetic phase data\n",
    "beta = 1/(5) # Inverse Temperature\n",
    "number_samples = 2500\n",
    "samples_para_test = run_metropolis(L, beta,number_samples,sample_interval=10*N_spins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6ed009aa-1066-439d-83e5-5a2a099ad806",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_para_test = np.ones(2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f2fa8d-51a5-4e29-bd69-21044ed7e95e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a99af7a6-76e8-409b-96c5-a057dbe7d81e",
   "metadata": {},
   "source": [
    "<font size=5>  $\\textrm{b) Training the model:}$   </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dd8515-aefc-44f8-92b9-01d2d9c53aa3",
   "metadata": {},
   "source": [
    "<font size=4>  $\\textrm{Setting up and organizing our data. Now we will organize our data such that Pytorch will recognize it.}$   </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07cc6c90-728c-4f28-a8d5-0e64d8acbe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93c98fee-d6cd-4280-8982-8e8442fb8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpinConfigurationDataset(Dataset):\n",
    "    def __init__(self, spin_configs, labels):\n",
    "        self.spin_configs = torch.tensor(spin_configs, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        spin_config = self.spin_configs[idx]\n",
    "        label = self.labels[idx]\n",
    "        return spin_config, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c912cbdb-9ca5-406f-9aa4-8ef5e825d711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfefbc37-3127-4d93-86b0-08f994d862bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torch.tensor(np.concatenate((samples_ferro,samples_para)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a791a7c-1d3d-4742-b13c-7202397197f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = torch.tensor(np.concatenate((label_ferro,label_para )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9a09f80-eea9-48ce-9620-9fff0f25d668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3722274/564826694.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.spin_configs = torch.tensor(spin_configs, dtype=torch.float32)\n",
      "/tmp/ipykernel_3722274/564826694.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels = torch.tensor(labels, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "dataset = SpinConfigurationDataset(training_data, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0703601c-bb1e-45fb-be9c-503e07c27051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader\n",
    "batch_size = 500\n",
    "shuffle = True\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2a1825-5909-4296-a7d3-9a7e9fffbdcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40373b4-88f5-4e61-adcf-c2f5208fe41e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2e8dbd4-99eb-4157-9cf0-e5029ca8635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.tensor(np.concatenate((samples_ferro_test,samples_para_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1bd8c7f-8076-496b-b0ae-c9cf2a649c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = torch.tensor(np.concatenate((label_ferro_test,label_para_test )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eaa3a3a8-3a82-42d0-a30b-a621fbec1d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3722274/564826694.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.spin_configs = torch.tensor(spin_configs, dtype=torch.float32)\n",
      "/tmp/ipykernel_3722274/564826694.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels = torch.tensor(labels, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "test_data_loader = SpinConfigurationDataset(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c4ca61e-44ba-4df0-80de-0034dd48d1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader\n",
    "batch_size = 500\n",
    "shuffle = True\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3665ca9c-d786-497f-83e8-c6c7fefe62fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fa3ad5060b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61a7549c-2b7c-4b81-98b5-fdab59ba1a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa3be43e550>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Define the neural network architecture\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        # x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a414c126-0605-4121-8578-f239dfe98099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "input_size = L*L \n",
    "hidden_size = 100\n",
    "output_size = 2  # Number of classes\n",
    "learning_rate = 0.001\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82061306-ec0b-4fb7-9f92-65d26b0ac46c",
   "metadata": {},
   "source": [
    "The `nn.CrossEntropyLoss` in PyTorch combines the operations of `nn.LogSoftmax` and `nn.NLLLoss` (negative log likelihood loss) in a single class. This is a commonly used loss function for classification tasks, particularly for multi-class classification (although ours is binary, but this work more generally for you to try stuff on your own!).\n",
    "\n",
    "Here's a detailed explanation of how `nn.CrossEntropyLoss` works:\n",
    "\n",
    "### Step-by-Step Breakdown\n",
    "\n",
    "1. **Raw Model Outputs (Logits):**\n",
    "   - Your neural network outputs raw scores, called logits, for each class. These logits are not probabilities and can take any value (positive or negative).\n",
    "   - Let's denote the logits for a single sample as $\\mathbf{z} = [z_1, z_2, \\ldots, z_C]$, where $C$ is the number of classes.\n",
    "\n",
    "2. **Softmax Function:**\n",
    "   - The softmax function is applied to the logits to convert them into probabilities. The softmax function is defined as:\n",
    "     <font size=4>$\n",
    "     \\sigma(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^C e^{z_j}}\n",
    "     $</font>\n",
    "   - This ensures that the output probabilities are in the range $[0, 1]$ and sum to $1$.\n",
    "\n",
    "3. **Log-Softmax:**\n",
    "   - Instead of applying the softmax function and then taking the logarithm, `nn.CrossEntropyLoss` directly computes the log-softmax. This is more numerically stable. The log-softmax for class \\(i\\) is defined as: \n",
    "     <font size=4>$\n",
    "     \\ \\log(\\sigma(\\mathbf{z})_i) = z_i - \\log\\left(\\sum_{j=1}^C e^{z_j}\\right)\n",
    "     $</font>\n",
    "\n",
    "4. **Negative Log Likelihood Loss (NLLLoss):**\n",
    "   - The loss for a single sample with true class label $y$ is given by:\n",
    "     $\n",
    "     \\ \\text{NLLLoss} = -\\log(\\sigma(\\mathbf{z})_y)\n",
    "     $\n",
    "   - This corresponds to the negative log probability of the true class.\n",
    "\n",
    "5. **Combining the Steps:**\n",
    "   - `nn.CrossEntropyLoss` combines the log-softmax and NLLLoss steps into one function for efficiency. The final loss for a batch of samples is the average (or sum, depending on the settings) of the individual losses.\n",
    "\n",
    "### Formula for Cross Entropy Loss\n",
    "The cross-entropy loss for a single sample can be written as:\n",
    "<font size=4>$\\text{CrossEntropyLoss}(\\mathbf{z}, y) = - \\log\\left(\\frac{e^{z_y}}{\\sum_{j=1}^C e^{z_j}}\\right)$ </font>\n",
    "where $z_y$ is the logit corresponding to the true class $y$.\n",
    "\n",
    "For a batch of $N$ samples, the average cross-entropy loss is:\n",
    "<font size=4>$\n",
    "\\text{CrossEntropyLoss}(\\mathbf{Z}, \\mathbf{y}) = -\\frac{1}{N} \\sum_{i=1}^N \\log\\left(\\frac{e^{z_{i,y_i}}}{\\sum_{j=1}^C e^{z_{i,j}}}\\right)\n",
    "$</font>\n",
    "where $z_{i,y_i}$ is the logit for the $i$-th sample corresponding to its true class $y_i$.\n",
    "\n",
    "### Practical Example in PyTorch\n",
    "\n",
    "Here's how we typically implement it `nn.CrossEntropyLoss` in a PyTorch model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "78db36d0-f241-4736-9bdc-4d2ae20d890b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.44697161167860033, Test Loss: 0.29559473545849324\n",
      "Epoch [2/30], Loss: 0.21996216028928756, Test Loss: 0.1585379368290305\n",
      "Epoch [3/30], Loss: 0.11760344505310058, Test Loss: 0.08671096526607872\n",
      "Epoch [4/30], Loss: 0.06500279381871224, Test Loss: 0.05117717612423003\n",
      "Epoch [5/30], Loss: 0.03962917514145374, Test Loss: 0.0332772844074294\n",
      "Epoch [6/30], Loss: 0.026622920669615267, Test Loss: 0.02378743175319396\n",
      "Epoch [7/30], Loss: 0.019471199670806526, Test Loss: 0.018109327238239346\n",
      "Epoch [8/30], Loss: 0.015066803805530072, Test Loss: 0.014418980653700418\n",
      "Epoch [9/30], Loss: 0.012151133362203836, Test Loss: 0.011851019423455\n",
      "Epoch [10/30], Loss: 0.010100263077765704, Test Loss: 0.01004483562564128\n",
      "Epoch [11/30], Loss: 0.008610045164823532, Test Loss: 0.008695519871870056\n",
      "Epoch [12/30], Loss: 0.0074588393326848745, Test Loss: 0.007635266881051939\n",
      "Epoch [13/30], Loss: 0.0065645945724099874, Test Loss: 0.006802698300644988\n",
      "Epoch [14/30], Loss: 0.005844850826542824, Test Loss: 0.006183959283708827\n",
      "Epoch [15/30], Loss: 0.005278116406407208, Test Loss: 0.0056447746451129205\n",
      "Epoch [16/30], Loss: 0.0047531651332974436, Test Loss: 0.005190591643154039\n",
      "Epoch [17/30], Loss: 0.004340775485616177, Test Loss: 0.004811534541944274\n",
      "Epoch [18/30], Loss: 0.003972936887294054, Test Loss: 0.004513270406881929\n",
      "Epoch [19/30], Loss: 0.003632623190060258, Test Loss: 0.0042244790033139\n",
      "Epoch [20/30], Loss: 0.0033332909806631505, Test Loss: 0.0040155960900439824\n",
      "Epoch [21/30], Loss: 0.0030827911396045238, Test Loss: 0.0037932061032424826\n",
      "Epoch [22/30], Loss: 0.0028303107421379535, Test Loss: 0.0036082209991323906\n",
      "Epoch [23/30], Loss: 0.002614747284678742, Test Loss: 0.003447000774473054\n",
      "Epoch [24/30], Loss: 0.0024399608140811325, Test Loss: 0.0033056900125295213\n",
      "Epoch [25/30], Loss: 0.0022596042254008353, Test Loss: 0.0031648890518858027\n",
      "Epoch [26/30], Loss: 0.0021152621833607555, Test Loss: 0.0030652571316855757\n",
      "Epoch [27/30], Loss: 0.0019512451603077353, Test Loss: 0.0029654998293855896\n",
      "Epoch [28/30], Loss: 0.0018249460263177752, Test Loss: 0.00288545411246414\n",
      "Epoch [29/30], Loss: 0.0017001846397761255, Test Loss: 0.0027942773822955133\n",
      "Epoch [30/30], Loss: 0.0015924566949252039, Test Loss: 0.0026811341595095657\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = FFNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for inputs, targets in data_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_data_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "\n",
    "    # Print average loss for this epoch\n",
    "    # print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(data_loader)}\")\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(data_loader)}, Test Loss: {test_loss / len(test_data_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "09222037-966b-4f7f-b84a-aa47060aeb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,\n",
       "        -1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1., -1., -1., -1.,  1.,\n",
       "         1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "         1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,\n",
       "        -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,\n",
       "        -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1., -1., -1., -1., -1.,\n",
       "        -1.,  1.])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e9c895d2-d173-4507-b408-b5ac4499ce12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3722274/4102808501.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  F.softmax(model(inputs))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3.4194e-04, 9.9966e-01], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(model(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a205cb34-9fc3-48dd-a602-c70c5029e454",
   "metadata": {},
   "source": [
    "<font size=5>  $\\textrm{c) Testing generalization:}$   </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1b1b72f-5b06-4997-a49b-51570b62cdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the ferromagnetic phase data\n",
    "beta = 1/(0.3) # Inverse Temperature\n",
    "number_samples = 2500\n",
    "General_ferro_test = run_metropolis(L, beta,number_samples,sample_interval=10*N_spins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41f8cb20-f477-418c-9a45-73b6e3da72f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ferro_general = np.zeros(2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0844bec-f5b7-4cf4-865c-0f996a72411c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0329aa6-a538-44a1-885f-83e4922c4496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the paramagnetic phase data\n",
    "beta = 1/(3.5) # Inverse Temperature\n",
    "number_samples = 2500\n",
    "General_para_test = run_metropolis(L, beta,number_samples,sample_interval=10*N_spins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4a99eea3-bc08-49ed-89cd-12b21c33f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_para_general = np.ones(2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353ca3db-fb26-489d-92fc-b06652296669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d6b7ff51-9fe5-4cdb-aa43-e8b80507c897",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_data = torch.tensor(np.concatenate((General_ferro_test,General_para_test)))\n",
    "\n",
    "gene_labels = torch.tensor(np.concatenate((label_ferro_general,label_para_general)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "437af9a6-f915-4a53-9688-f9bf77572dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3722274/564826694.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.spin_configs = torch.tensor(spin_configs, dtype=torch.float32)\n",
      "/tmp/ipykernel_3722274/564826694.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.labels = torch.tensor(labels, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "dataset_gen = SpinConfigurationDataset(gene_data, gene_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3fd11f12-3337-45a1-b116-9a712b729388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader\n",
    "batch_size = 500\n",
    "shuffle = True\n",
    "data_loader_gene = DataLoader(dataset_gen, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41aeace-2f0e-4557-9144-99877730fe1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "73529352-85ac-4c04-a04f-b4f29cddef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in data_loader_gene:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "90ca6551-0560-423e-a4cf-8e7cfdb5b9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.776701295748353e-05\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Loss: {test_loss / len(test_data_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e15e88-5b90-4efd-bd5f-3cf8ea39f327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d65b650-3a2e-4f7e-8e79-3bdaff0e7f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4aa90eb8-6cb9-4474-969c-b1e12e2899cf",
   "metadata": {},
   "source": [
    "<font size=5>  $\\text{Benchmarking our model}$   </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680b334f-d54a-441f-8f0d-2b6cfbc3b6f9",
   "metadata": {},
   "source": [
    "<font size=4> $\\text{Precision}$ </font>\n",
    "\\begin{equation}\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "\\end{equation}\n",
    "\n",
    "<font size=4> $\\text{Recall (Sensitivity or True Positive Rate)}$ </font>\n",
    "\\begin{equation}\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "\\end{equation}\n",
    "\n",
    "<font size=4> $\\text{F1 Score}$ </font>\n",
    "\\begin{equation}\n",
    "\\text{F1 Score} = \\frac{2 \\cdot \\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "\\end{equation}\n",
    "\n",
    "<font size=4> $\\text{Accuracy}$ </font>\n",
    "\\begin{equation}\n",
    "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "\\end{equation}\n",
    "\n",
    "<font size=4> $\\text{False Positive Rate}$ </font>\n",
    "\\begin{equation}\n",
    "\\text{FPR} = \\frac{FP}{FP + TN}\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e67ec6-f4ab-4971-b8b6-70a02e2f4a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2f5ff5b1-e17c-4259-b02f-c6b413d2f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy:  The ratio of correctly predicted samples to the total number of samples.\n",
    "\n",
    "# Precision: The ratio of true positive predictions to the total number of positive predictions (true positives + false positives). \n",
    "\n",
    "# Recall: The ratio of true positive predictions to the total number of actual positives (true positives + false negatives).\n",
    "\n",
    "# F1 Score: The harmonic mean of precision and recall. It balances both metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f597ed5c-bc7b-4430-bbd1-f69405d72825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Perform a forward pass to get the logits\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f0ed7fcc-0b1c-4928-a4e3-40cfe7f797a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply sigmoid to get probabilities\n",
    "probs = F.softmax(logits,dim=1)\n",
    "\n",
    "\n",
    "# Determine the predicted class (0 or 1) based on the threshold of 0.5\n",
    "predictions = (probs >= 0.5).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ff44be84-d4c9-443d-bf20-dfba4d8558a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions and labels to numpy arrays for scikit-learn functions\n",
    "predictions_np = np.argmax(predictions.cpu().numpy(), axis=1)\n",
    "labels_np = targets.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908eaa19-cfc9-45d1-923a-00fe73180cc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5a9c1a53-830a-4935-aae9-6db3b47b69e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "695e4607-8b8a-41d1-92ab-71db0e2c20b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1ea1f08a-12f1-445f-a33d-656854c2395a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9980\n",
      "Precision: 1.0000\n",
      "Recall: 0.9957\n",
      "F1 Score: 0.9979\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy\n",
    "accuracy = accuracy_score(labels_np, predictions_np)\n",
    "\n",
    "# Compute precision\n",
    "precision = precision_score(labels_np, predictions_np)\n",
    "\n",
    "# Compute recall\n",
    "recall = recall_score(labels_np, predictions_np)\n",
    "\n",
    "# Compute F1 score\n",
    "f1 = f1_score(labels_np, predictions_np)\n",
    "\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b046702d-af18-4879-9244-b5b1901b0c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcc271a-9f92-4e8a-9d79-681aa7e08b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e3fd20-a6a2-470c-9956-93c71e7fe3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89908668-09e2-4a43-9872-93d7ea6e628a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf6f9d3-ef6b-49cb-abe8-803a6e84d32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871ff476-3663-4e97-befe-e24dcb360e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c3bd79-b729-4a3d-a22e-2b2a407ec608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa0da6f-87f5-4915-b052-92feaf046209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "condaforge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
